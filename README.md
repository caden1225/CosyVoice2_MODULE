# CosyVoice2 æ¨¡å—åŒ–ç‰ˆæœ¬

CosyVoice2çš„æ¨¡å—åŒ–å°è£…,æ”¯æŒä½œä¸ºPythonåŒ…å¯¼å…¥ä½¿ç”¨,å¹¶æ–°å¢**æµå¼æ–‡æœ¬åˆ†å—æ¨ç†åŠŸèƒ½**ã€‚

## ğŸ“¦ é¡¹ç›®ç‰¹æ€§

### æ ¸å¿ƒåŠŸèƒ½

- âœ… **æ¨¡å—åŒ–å°è£…**: å¯ä½œä¸ºPythonåŒ… `import cosyvoice` ä½¿ç”¨
- âœ… **Zero-shotè¯­éŸ³å…‹éš†**: ä½¿ç”¨å‚è€ƒéŸ³é¢‘åˆæˆç›®æ ‡è¯´è¯äººå£°éŸ³
- âœ… **é¢„ç½®éŸ³è‰²åˆæˆ**: ä½¿ç”¨é¢„è®­ç»ƒçš„å¤šç§éŸ³è‰²
- âœ… **è·¨è¯­è¨€åˆæˆ**: æ”¯æŒä¸­è‹±æ–‡ç­‰å¤šè¯­è¨€
- âœ… **æµå¼æ¨ç†**: æ”¯æŒæµå¼å’Œéæµå¼ä¸¤ç§è¾“å‡ºæ¨¡å¼
- âœ… **æµå¼åˆ†å—æ¨ç†**: æ–°å¢åŠŸèƒ½,æ”¯æŒæ–‡æœ¬åˆ†å—è¾“å…¥å¹¶ä¿æŒè¯­ä¹‰è¿è´¯æ€§

### æ–°å¢åŠŸèƒ½: æµå¼æ–‡æœ¬åˆ†å—æ¨ç†

æ”¯æŒå°†é•¿æ–‡æœ¬åˆ†å—å¤„ç†,åŒæ—¶ä¿æŒè·¨chunkçš„è¯­ä¹‰ã€éŸµå¾‹å’ŒéŸ³è‰²è¿è´¯æ€§ã€‚

**æ ¸å¿ƒä¼˜åŠ¿**:
- ğŸ”„ **è¯­ä¹‰è¿è´¯**: è·¨chunkä¿æŒå®Œæ•´ä¸Šä¸‹æ–‡
- ğŸµ **éŸµå¾‹è‡ªç„¶**: å¹³æ»‘çš„è¯­è°ƒå’ŒèŠ‚å¥è¿‡æ¸¡
- ğŸ¤ **éŸ³è‰²ä¸€è‡´**: å…¨ç¨‹ä¿æŒç¨³å®šéŸ³è‰²
- âš¡ **å»¶è¿Ÿä¼˜åŒ–**: æ”¯æŒå¯è°ƒçš„chunkå¤§å°,å®ç°ä½å»¶è¿Ÿè¾“å‡º

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### åŸºç¡€ä½¿ç”¨

#### 1. é¢„ç½®éŸ³è‰²åˆæˆ

```python
from cosyvoice.cli.cosyvoice import CosyVoice2

# åˆå§‹åŒ–æ¨¡å‹
model = CosyVoice2('/path/to/CosyVoice2-0.5B')

# åˆæˆè¯­éŸ³
for result in model.inference_sft(
    tts_text="ä»Šå¤©å¤©æ°”å¾ˆå¥½",
    spk_id="girl_zh",
    stream=False
):
    audio = result['tts_speech']
    # ä¿å­˜æˆ–æ’­æ”¾éŸ³é¢‘...
```

#### 2. Zero-shotè¯­éŸ³å…‹éš†

```python
from cosyvoice.utils.file_utils import load_wav

# åŠ è½½å‚è€ƒéŸ³é¢‘
prompt_speech = load_wav('reference.wav', 16000)

# å…‹éš†å£°éŸ³åˆæˆ
for result in model.inference_zero_shot(
    tts_text="è¿™æ˜¯è¦åˆæˆçš„æ–‡æœ¬",
    prompt_text="å‚è€ƒéŸ³é¢‘çš„æ–‡æœ¬",
    prompt_speech_16k=prompt_speech,
    stream=False
):
    audio = result['tts_speech']
```

#### 3. æµå¼æ–‡æœ¬åˆ†å—æ¨ç† (æ–°åŠŸèƒ½)

```python
# å‡†å¤‡æ–‡æœ¬chunks
text_chunks = ["ä»Šå¤©å¤©æ°”å¾ˆå¥½", "é€‚åˆå‡ºå»æ•£æ­¥", "å‘¼å¸æ–°é²œç©ºæ°”"]

# åˆ†å—æ¨ç†,ä¿æŒè¿è´¯æ€§
for result in model.inference_sft_chunked(
    text_chunks=text_chunks,
    spk_id="girl_zh",
    stream=True,
    token_hop_len=15,  # æ§åˆ¶è¾“å‡ºchunkå¤§å°
    mel_cache_len=6    # æ§åˆ¶è¾¹ç•Œå¹³æ»‘åº¦
):
    audio = result['tts_speech']
    # å®æ—¶å¤„ç†éŸ³é¢‘...
```

## ğŸ“– APIæ–‡æ¡£

### CosyVoice2 ç±»

#### åˆå§‹åŒ–

```python
CosyVoice2(
    model_dir: str,              # æ¨¡å‹è·¯å¾„
    load_jit: bool = False,      # æ˜¯å¦åŠ è½½JITä¼˜åŒ–æ¨¡å‹
    load_trt: bool = False,      # æ˜¯å¦åŠ è½½TensorRTä¼˜åŒ–
    load_vllm: bool = False,     # æ˜¯å¦åŠ è½½vLLMåŠ é€Ÿ
    fp16: bool = False           # æ˜¯å¦ä½¿ç”¨FP16ç²¾åº¦
)
```

#### æ–¹æ³•åˆ—è¡¨

##### `inference_sft()`
ä½¿ç”¨é¢„ç½®éŸ³è‰²åˆæˆè¯­éŸ³

```python
inference_sft(
    tts_text: str,               # è¦åˆæˆçš„æ–‡æœ¬
    spk_id: str,                 # è¯´è¯äººID (å¦‚ "girl_zh", "man_zh")
    stream: bool = False,        # æ˜¯å¦æµå¼è¾“å‡º
    speed: float = 1.0,          # è¯­é€Ÿå€æ•°
    text_frontend: bool = True   # æ˜¯å¦è¿›è¡Œæ–‡æœ¬å½’ä¸€åŒ–
) -> Generator[dict, None, None]
```

**å¯ç”¨è¯´è¯äººID**: ä½¿ç”¨ `model.list_available_spks()` æŸ¥çœ‹

##### `inference_zero_shot()`
Zero-shotè¯­éŸ³å…‹éš†

```python
inference_zero_shot(
    tts_text: str,                    # è¦åˆæˆçš„æ–‡æœ¬
    prompt_text: str,                 # å‚è€ƒéŸ³é¢‘çš„æ–‡æœ¬
    prompt_speech_16k: torch.Tensor,  # å‚è€ƒéŸ³é¢‘ (16kHz)
    zero_shot_spk_id: str = '',       # å¯é€‰çš„é›¶æ ·æœ¬ID
    stream: bool = False,
    speed: float = 1.0
) -> Generator[dict, None, None]
```

##### `inference_cross_lingual()`
è·¨è¯­è¨€åˆæˆ

```python
inference_cross_lingual(
    tts_text: str,                    # è¦åˆæˆçš„æ–‡æœ¬
    prompt_speech_16k: torch.Tensor,  # å‚è€ƒéŸ³é¢‘
    stream: bool = False
) -> Generator[dict, None, None]
```

##### `inference_sft_chunked()` (æ–°å¢)
æµå¼æ–‡æœ¬åˆ†å—æ¨ç†

```python
inference_sft_chunked(
    text_chunks: List[str] | Generator[str],  # æ–‡æœ¬å—åˆ—è¡¨æˆ–ç”Ÿæˆå™¨
    spk_id: str,                              # è¯´è¯äººID
    stream: bool = False,                     # æ˜¯å¦æµå¼è¾“å‡ºéŸ³é¢‘
    speed: float = 1.0,                       # è¯­é€Ÿå€æ•°
    text_frontend: bool = True,               # æ–‡æœ¬å½’ä¸€åŒ–
    token_hop_len: int = None,                # è¾“å‡ºchunkå¤§å° (å¯é€‰)
    mel_cache_len: int = None                 # è¾¹ç•Œå¹³æ»‘ç¼“å­˜ (å¯é€‰)
) -> Generator[dict, None, None]
```

**å‚æ•°è¯´æ˜**:
- `text_chunks`: æ–‡æœ¬å—åˆ—è¡¨,æ¯ä¸ªå—ä¼šè¢«ç‹¬ç«‹å½’ä¸€åŒ–ä½†ä½œä¸ºè¿ç»­æµå¤„ç†
- `token_hop_len`: æ§åˆ¶æµå¼è¾“å‡ºæ—¶æ¯æ¬¡yieldçš„éŸ³é¢‘å¤§å°
  - è¶Šå° â†’ å»¶è¿Ÿè¶Šä½,ä½†yieldæ¬¡æ•°è¶Šå¤š
  - è¶Šå¤§ â†’ å•æ¬¡è¾“å‡ºæ›´é•¿,å»¶è¿Ÿç•¥é«˜ä½†æ›´æµç•…
  - é»˜è®¤: 25 (çº¦1ç§’éŸ³é¢‘)
- `mel_cache_len`: æ§åˆ¶chunkè¾¹ç•Œçš„å¹³æ»‘è¿‡æ¸¡
  - è¶Šå¤§ â†’ è¿‡æ¸¡è¶Šå¹³æ»‘
  - é»˜è®¤: 8

**è¿”å›å€¼**:
ç”Ÿæˆå™¨,æ¯æ¬¡yieldä¸€ä¸ªå­—å…¸ `{'tts_speech': torch.Tensor}`

## ğŸ›ï¸ æ€§èƒ½ä¼˜åŒ–

### Chunkå‚æ•°é…ç½®è¯´æ˜

#### å‚æ•°ä½ç½®

æµå¼åˆ†å—æ¨ç†çš„chunkå¤§å°ç”±ä»¥ä¸‹ä¸¤ä¸ªå‚æ•°æ§åˆ¶:

1. **è¾“å…¥å±‚é¢ - æ–‡æœ¬chunkå¤§å°** (ç”¨æˆ·æ§åˆ¶)
   - **ä½ç½®**: `inference_sft_chunked()` çš„ `text_chunks` å‚æ•°
   - **ä½œç”¨**: æ§åˆ¶è¾“å…¥æ–‡æœ¬çš„åˆ†å—æ–¹å¼
   - **é…ç½®æ–¹å¼**:
   ```python
   # æ–¹å¼1: æ‰‹åŠ¨åˆ†å—
   text_chunks = ["ç¬¬ä¸€æ®µæ–‡æœ¬", "ç¬¬äºŒæ®µæ–‡æœ¬", "ç¬¬ä¸‰æ®µæ–‡æœ¬"]

   # æ–¹å¼2: æŒ‰å­—ç¬¦é•¿åº¦è‡ªåŠ¨åˆ†å—
   long_text = "å¾ˆé•¿çš„æ–‡æœ¬å†…å®¹..."
   chunk_size = 20  # æ¯å—20ä¸ªå­—ç¬¦
   text_chunks = [long_text[i:i+chunk_size] for i in range(0, len(long_text), chunk_size)]

   # æ–¹å¼3: ä½¿ç”¨ç”Ÿæˆå™¨ (å®æ—¶æµ)
   def text_stream():
       for sentence in sentences:
           yield sentence
   text_chunks = text_stream()
   ```

2. **è¾“å‡ºå±‚é¢ - éŸ³é¢‘chunkå¤§å°** (æ¨¡å‹æ§åˆ¶)
   - **å‚æ•°å**: `token_hop_len` å’Œ `mel_cache_len`
   - **ä½ç½®**: `inference_sft_chunked()` æ–¹æ³•çš„å¯é€‰å‚æ•°
   - **é…ç½®æ–¹å¼**:
   ```python
   # ç›´æ¥åœ¨è°ƒç”¨æ—¶æŒ‡å®š
   for result in model.inference_sft_chunked(
       text_chunks=text_chunks,
       spk_id="girl_zh",
       stream=True,
       token_hop_len=15,   # â† è¾“å‡ºchunkå¤§å°
       mel_cache_len=6     # â† è¾¹ç•Œå¹³æ»‘ç¼“å­˜
   ):
       audio = result['tts_speech']
   ```

#### å‚æ•°ä½œç”¨æœºåˆ¶

```
è¾“å…¥æ–‡æœ¬ â†’ [æ–‡æœ¬åˆ†å—] â†’ æ–‡æœ¬chunks â†’ [Tokenç”Ÿæˆ] â†’ Tokenæµ â†’ [éŸ³é¢‘ç”Ÿæˆ] â†’ éŸ³é¢‘chunks
           â†‘ç”¨æˆ·æ§åˆ¶                                    â†‘token_hop_lenæ§åˆ¶
                                                        â†‘mel_cache_lenå¹³æ»‘
```

**åŒå±‚chunkæ¶æ„**:
- **ç¬¬1å±‚ (è¾“å…¥)**: æ–‡æœ¬è¯­ä¹‰chunk - ç”±ç”¨æˆ·æ ¹æ®è¯­ä¹‰è¾¹ç•Œåˆ’åˆ†
- **ç¬¬2å±‚ (è¾“å‡º)**: éŸ³é¢‘æ—¶åºchunk - ç”±`token_hop_len`æ§åˆ¶æµå¼yieldé¢‘ç‡

#### å®Œæ•´é…ç½®ç¤ºä¾‹

```python
from cosyvoice.cli.cosyvoice import CosyVoice2

# 1. åˆå§‹åŒ–æ¨¡å‹
model = CosyVoice2('/path/to/CosyVoice2-0.5B')

# 2. é…ç½®è¾“å…¥chunk (ç”¨æˆ·å±‚é¢)
text = "äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•ï¼Œæ·±åˆ»æ”¹å˜ç€æˆ‘ä»¬çš„ç”Ÿæ´»æ–¹å¼å’Œå·¥ä½œæ¨¡å¼ã€‚"
text_chunks = ["äººå·¥æ™ºèƒ½æŠ€æœ¯", "æ­£åœ¨å¿«é€Ÿå‘å±•", "æ·±åˆ»æ”¹å˜ç€", "æˆ‘ä»¬çš„ç”Ÿæ´»æ–¹å¼", "å’Œå·¥ä½œæ¨¡å¼"]

# 3. é…ç½®è¾“å‡ºchunkå‚æ•° (æ¨¡å‹å±‚é¢)
for result in model.inference_sft_chunked(
    text_chunks=text_chunks,      # è¾“å…¥chunké…ç½®
    spk_id="girl_zh",
    stream=True,                  # å¯ç”¨æµå¼è¾“å‡º
    token_hop_len=15,            # è¾“å‡ºchunkå¤§å°: æ¯15ä¸ªtoken yieldä¸€æ¬¡
    mel_cache_len=6              # è¾¹ç•Œç¼“å­˜: 6å¸§melç”¨äºå¹³æ»‘è¿‡æ¸¡
):
    audio_chunk = result['tts_speech']
    # å®æ—¶å¤„ç†æ¯ä¸ªéŸ³é¢‘chunk
    play_or_stream(audio_chunk)
```

### æµå¼åˆ†å—æ¨ç†å‚æ•°è°ƒä¼˜

æ ¹æ®å®é™…æµ‹è¯•,ä¸åŒçš„`token_hop_len`å’Œ`mel_cache_len`ç»„åˆé€‚ç”¨äºä¸åŒåœºæ™¯:

#### æ¨èé…ç½®

| åœºæ™¯ | token_hop_len | mel_cache_len | é¦–æ¬¡å“åº” | ç‰¹ç‚¹ |
|------|--------------|---------------|---------|------|
| **å®æ—¶å¯¹è¯** | 8 | 4 | ~1.3s | æœ€å¿«å“åº”,é€‚åˆè¯­éŸ³åŠ©æ‰‹ |
| **é€šç”¨åº”ç”¨** | 15 | 6 | ~1.5s | **æ¨èé»˜è®¤é…ç½®** |
| **é«˜è´¨é‡æ’­æŠ¥** | 25 | 8 | ~1.9s | æœ€ä½³æ•ˆç‡,é€‚åˆæœ—è¯» |

#### ä½¿ç”¨ç¤ºä¾‹

```python
# å®æ—¶å¯¹è¯åœºæ™¯ (è¿½æ±‚æœ€ä½å»¶è¿Ÿ)
for result in model.inference_sft_chunked(
    text_chunks=["ä½ å¥½", "æœ‰ä»€ä¹ˆ", "å¯ä»¥å¸®æ‚¨"],
    spk_id="girl_zh",
    stream=True,
    token_hop_len=8,   # è¶…ä½å»¶è¿Ÿ
    mel_cache_len=4
):
    play_immediately(result['tts_speech'])

# é€šç”¨åœºæ™¯ (æ¨èé…ç½®)
for result in model.inference_sft_chunked(
    text_chunks=["äººå·¥æ™ºèƒ½", "æ­£åœ¨å‘å±•", "æ”¹å˜ä¸–ç•Œ"],
    spk_id="girl_zh",
    stream=True,
    token_hop_len=15,  # å¹³è¡¡é…ç½®
    mel_cache_len=6
):
    process_audio(result['tts_speech'])

# æ–°é—»æ’­æŠ¥åœºæ™¯ (è¿½æ±‚é«˜è´¨é‡)
for result in model.inference_sft_chunked(
    text_chunks=news_paragraphs,
    spk_id="woman_zh",
    stream=True,
    token_hop_len=25,  # é«˜æ•ˆç‡
    mel_cache_len=8
):
    buffer_and_play(result['tts_speech'])
```

### æ€§èƒ½è¯´æ˜

åŸºäºç³»ç»ŸåŒ–æµ‹è¯•çš„ç»“æœ:

- **token_hop_len < 8**: âŒ ä¸æ¨è,åè€Œå¯¼è‡´æ›´é«˜å»¶è¿Ÿ
- **token_hop_len = 8-10**: âš¡ æœ€ä½å»¶è¿Ÿ,é€‚åˆå®æ—¶åœºæ™¯
- **token_hop_len = 15**: âœ… **æœ€ä½³å¹³è¡¡ç‚¹**,æ¨èå¤§å¤šæ•°åœºæ™¯ä½¿ç”¨
- **token_hop_len = 20-25**: ğŸ“ˆ æœ€ä½³æ•ˆç‡,é€‚åˆæ‰¹å¤„ç†

## ğŸ’» ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1: ç®€å•çš„TTS

```python
from cosyvoice.cli.cosyvoice import CosyVoice2
import soundfile as sf

# åˆå§‹åŒ–
model = CosyVoice2('/path/to/model')

# åˆæˆ
for result in model.inference_sft("ä»Šå¤©å¤©æ°”çœŸå¥½", spk_id="girl_zh"):
    audio = result['tts_speech'].squeeze().cpu().numpy()
    sf.write('output.wav', audio, model.sample_rate)
```

### ç¤ºä¾‹2: æµå¼åˆ†å—å¤„ç†

```python
# é•¿æ–‡æœ¬åˆ†å—
long_text = "è¿™æ˜¯ä¸€æ®µå¾ˆé•¿çš„æ–‡æœ¬..."
chunks = [long_text[i:i+20] for i in range(0, len(long_text), 20)]

# æµå¼åˆæˆ
audio_segments = []
for result in model.inference_sft_chunked(
    text_chunks=chunks,
    spk_id="girl_zh",
    stream=True,
    token_hop_len=15
):
    audio_segments.append(result['tts_speech'])

# åˆå¹¶éŸ³é¢‘
import torch
full_audio = torch.cat(audio_segments, dim=1)
```

### ç¤ºä¾‹3: å®æ—¶æ–‡æœ¬æµå¤„ç†

```python
def text_stream():
    """æ¨¡æ‹Ÿå®æ—¶æ–‡æœ¬æµ"""
    texts = ["å®æ—¶", "è¯­éŸ³", "åˆæˆ", "æ¼”ç¤º"]
    for text in texts:
        yield text
        time.sleep(0.1)  # æ¨¡æ‹Ÿå»¶è¿Ÿ

# ä½¿ç”¨Generatorè¾“å…¥
for result in model.inference_sft_chunked(
    text_chunks=text_stream(),
    spk_id="girl_zh",
    stream=True,
    token_hop_len=8  # ä½å»¶è¿Ÿé…ç½®
):
    audio = result['tts_speech']
    # ç«‹å³æ’­æ”¾æˆ–å‘é€
```

### ç¤ºä¾‹4: Zero-shotå…‹éš†

```python
from cosyvoice.utils.file_utils import load_wav

# åŠ è½½å‚è€ƒéŸ³é¢‘
prompt_wav = load_wav('reference.wav', 16000)

# å…‹éš†å£°éŸ³
for result in model.inference_zero_shot(
    tts_text="ä½¿ç”¨å…‹éš†çš„å£°éŸ³è¯´è¿™å¥è¯",
    prompt_text="å‚è€ƒéŸ³é¢‘çš„æ–‡æœ¬å†…å®¹",
    prompt_speech_16k=prompt_wav
):
    audio = result['tts_speech'].squeeze().cpu().numpy()
    sf.write('cloned.wav', audio, model.sample_rate)
```

## ğŸ”¬ æŠ€æœ¯å®ç°ç»†èŠ‚

### Chunkæ¨¡å¼çš„å®ç°åŸç†

#### åˆ©ç”¨çš„ç°æœ‰æ¨¡å‹ç»“æ„

`inference_sft_chunked` æ–¹æ³•**é›¶ä¿®æ”¹**æ ¸å¿ƒæ¨¡å‹ä»£ç ï¼Œå®Œå…¨åŸºäºCosyVoice2å·²æœ‰çš„åŠŸèƒ½å®ç°ï¼š

1. **æ ¸å¿ƒæœºåˆ¶: LLMçš„`inference_bistream`æ–¹æ³•**
   - **ä½ç½®**: `cosyvoice/llm/llm.py:505-602`
   - **åŸæœ‰åŠŸèƒ½**: æ¥å—**Generatorç±»å‹**çš„textè¾“å…¥ï¼Œç”¨äºæµå¼æ¨ç†
   - **åˆ©ç”¨æ–¹å¼**: å°†å¤šä¸ªæ–‡æœ¬chunkçš„tokenä½œä¸ºè¿ç»­çš„Generatoræµè¾“å…¥
   ```python
   # llm.pyä¸­çš„å…³é”®æ–¹æ³•
   def inference_bistream(self, text: Generator, ...):
       # æ¥å—Generatorè¾“å…¥,é€æ­¥æ¶ˆè´¹token
       for text_token in text:
           # ç»´æŠ¤KV-cache,ä¿æŒä¸Šä¸‹æ–‡è¿ç»­
   ```

2. **çŠ¶æ€ç®¡ç†: UUIDä¼šè¯æœºåˆ¶**
   - **ä½ç½®**: `cosyvoice/cli/model.py`
   - **åŸæœ‰åŠŸèƒ½**: ä½¿ç”¨UUIDæ ‡è¯†ä¸€æ¬¡æ¨ç†ä¼šè¯ï¼Œè·¨å¤šæ¬¡yieldç»´æŠ¤ç¼“å­˜
   - **åˆ©ç”¨æ–¹å¼**: å•æ¬¡`inference_sft_chunked`è°ƒç”¨ç”Ÿæˆä¸€ä¸ªUUIDï¼Œæ‰€æœ‰chunkå…±äº«
   ```python
   # model.pyä¸­çš„UUIDæœºåˆ¶
   uuid = str(uuid4())  # ä¸€æ¬¡è°ƒç”¨ç”Ÿæˆä¸€ä¸ªä¼šè¯ID
   self.llm_cache[uuid] = {}      # LLMçš„KV-cache
   self.flow_cache[uuid] = {}     # Flowçš„melç¼“å­˜
   self.hift_cache[uuid] = {}     # HiFiGANçš„éŸ³é¢‘ç¼“å­˜
   ```

3. **æµå¼è¾“å‡º: Flowå’ŒHiFiGANçš„streamingæ”¯æŒ**
   - **Flowä½ç½®**: `cosyvoice/flow/flow.py:161` (`pre_lookahead_len=3`)
   - **HiFiGANç¼“å­˜**: `cosyvoice/cli/model.py:272-277` (mel_cache_len, speech_window)
   - **åŸæœ‰åŠŸèƒ½**: æ”¯æŒ`stream=True`å‚æ•°è¿›è¡Œå¢é‡éŸ³é¢‘ç”Ÿæˆ
   - **åˆ©ç”¨æ–¹å¼**: é€šè¿‡`token_hop_len`æ§åˆ¶æ¯æ¬¡yieldçš„éŸ³é¢‘é•¿åº¦

#### å®ç°æµç¨‹

```
ç”¨æˆ·è°ƒç”¨ inference_sft_chunked(text_chunks=[chunk1, chunk2, chunk3])
    â†“
ç”ŸæˆUUID (å¦‚: "a1b2c3d4-...")  â† ä¼šè¯æ ‡è¯†
    â†“
åˆ›å»º text_token_generator():
    for chunk in text_chunks:
        normalized = frontend.text_normalize(chunk)  â† é€ä¸ªå½’ä¸€åŒ–
        text_token = frontend._extract_text_token(normalized)
        yield tokené€ä¸ª                               â† Generatorè¾“å‡º
    â†“
è°ƒç”¨ model.tts(text=generator, uuid=uuid, ...)
    â†“
LLM.inference_bistream(text=generator):          â† æ ¸å¿ƒï¼æ¥å—Generator
    for token in text:                            â† æ¶ˆè´¹æ‰€æœ‰chunkçš„token
        ç»´æŠ¤ llm_cache[uuid]                       â† KV-cacheä¿æŒè¿è´¯
        yield speech_token
    â†“
Flow.forward(speech_token, streaming=True):
    ä½¿ç”¨ flow_cache[uuid]                          â† melç¼“å­˜ä¿æŒå¹³æ»‘
    æ¯ token_hop_len ä¸ªtoken yieldä¸€æ¬¡mel
    â†“
HiFiGAN.inference(mel):
    ä½¿ç”¨ hift_cache[uuid]                          â† éŸ³é¢‘ç¼“å­˜æ·¡å…¥æ·¡å‡º
    ä½¿ç”¨ speech_window (hamming) å¹³æ»‘è¾¹ç•Œ
    yield audio_chunk
    â†“
è¿”å›ç»™ç”¨æˆ·
```

#### ä¸åŸæœ‰`inference_sft`çš„åŒºåˆ«

| æ–¹é¢ | inference_sft (ä¼ ç»Ÿ) | inference_sft_chunked (æ–°) |
|------|---------------------|---------------------------|
| **æ–‡æœ¬è¾“å…¥** | å•ä¸ªå­—ç¬¦ä¸² | å¤šä¸ªchunkçš„Generator |
| **UUIDç”Ÿå‘½å‘¨æœŸ** | æ¯æ¬¡è°ƒç”¨æ–°å»º | æ•´ä¸ªchunkåºåˆ—å…±äº« |
| **LLMè¾“å…¥ç±»å‹** | `text: torch.Tensor` | `text: Generator` â†’ è§¦å‘`inference_bistream` |
| **ä¸Šä¸‹æ–‡è¿ç»­æ€§** | å•æ¬¡ç‹¬ç«‹ | è·¨chunkä¿æŒKV-cache |
| **é€‚ç”¨åœºæ™¯** | çŸ­æ–‡æœ¬/ç‹¬ç«‹å¥å­ | é•¿æ–‡æœ¬/è¿ç»­å¯¹è¯ |

### è¯·æ±‚åŒºåˆ†æœºåˆ¶

#### å¦‚ä½•åŒºåˆ†åŒä¸€è¯·æ±‚çš„ä¸åŒchunk

**ç­”æ¡ˆ: ä¸éœ€è¦åŒºåˆ†** - è¿™æ˜¯è®¾è®¡çš„å·§å¦™ä¹‹å¤„ï¼

- **ç”¨æˆ·è§†è§’**: ä¼ å…¥`text_chunks`åˆ—è¡¨æˆ–ç”Ÿæˆå™¨
- **æ¨¡å‹è§†è§’**: çœ‹åˆ°çš„æ˜¯**è¿ç»­çš„tokenæµ**ï¼Œå®Œå…¨ä¸çŸ¥é“chunkè¾¹ç•Œ
- **å®ç°æ–¹å¼**:
  ```python
  def text_token_generator():
      for chunk in text_chunks:  # éå†æ‰€æœ‰chunk
          text_token = process(chunk)
          for i in range(text_token.shape[1]):
              yield text_token[:, i:i+1]  # é€token yieldï¼Œæ— è¾¹ç•Œæ ‡è®°
  ```

- **è¿è´¯æ€§ä¿è¯**: LLMçš„`inference_bistream`å°†æ‰€æœ‰tokenè§†ä¸ºä¸€ä¸ªè¿ç»­åºåˆ—ï¼Œè‡ªç„¶ç»´æŠ¤ä¸Šä¸‹æ–‡

#### å¦‚ä½•åŒºåˆ†ä¸åŒçš„è¯·æ±‚

**å…³é”®æœºåˆ¶: UUIDä¼šè¯ç®¡ç†**

1. **æ¯æ¬¡è°ƒç”¨ç”Ÿæˆæ–°UUID**
   ```python
   # cosyvoice.py: inference_sft_chunked
   def inference_sft_chunked(self, text_chunks, ...):
       # æ¯æ¬¡è°ƒç”¨è¿™ä¸ªæ–¹æ³•æ—¶ï¼Œå†…éƒ¨ä¼šç”Ÿæˆæ–°UUID
       model_input = {...}
       for output in self.model.tts(**model_input):  # â† è¿™é‡Œç”Ÿæˆæ–°UUID
           yield output
   ```

2. **UUIDåœ¨model.tts()ä¸­ç”Ÿæˆ**
   ```python
   # model.py: ttsæ–¹æ³•
   def tts(self, text, ...):
       uuid = str(uuid4())  # â† æ–°è¯·æ±‚ = æ–°UUID

       # æ‰€æœ‰ç¼“å­˜ä»¥UUIDä¸ºkey
       self.llm_cache[uuid] = {}
       self.flow_cache[uuid] = {}
       self.hift_cache[uuid] = {}

       # æ¨ç†å®Œæˆåæ¸…ç†
       del self.llm_cache[uuid]
       del self.flow_cache[uuid]
       del self.hift_cache[uuid]
   ```

3. **è¯·æ±‚éš”ç¦»ç¤ºä¾‹**
   ```python
   # è¯·æ±‚1
   for audio in model.inference_sft_chunked(
       text_chunks=["ä½ å¥½", "ä¸–ç•Œ"],  # UUID-1234
       spk_id="girl_zh"
   ):
       play(audio)  # ä½¿ç”¨cache[UUID-1234]

   # è¯·æ±‚2 (å®Œå…¨ç‹¬ç«‹)
   for audio in model.inference_sft_chunked(
       text_chunks=["å†è§", "æœ‹å‹"],  # UUID-5678 (æ–°çš„!)
       spk_id="girl_zh"
   ):
       play(audio)  # ä½¿ç”¨cache[UUID-5678]ï¼Œä¸è¯·æ±‚1å®Œå…¨éš”ç¦»
   ```

#### ç¼“å­˜ç”Ÿå‘½å‘¨æœŸ

```
è°ƒç”¨å¼€å§‹                      è°ƒç”¨ç»“æŸ
   â†“                            â†“
[ç”ŸæˆUUID] â†’ [åˆ›å»ºç¼“å­˜] â†’ [é€chunkå¤„ç†] â†’ [æ¸…ç†ç¼“å­˜]
   uuid-A      cache[A]={}    ä½¿ç”¨cache[A]   del cache[A]

ä¸‹æ¬¡è°ƒç”¨å¼€å§‹
   â†“
[ç”ŸæˆUUID] â†’ [åˆ›å»ºç¼“å­˜] â†’ ...
   uuid-B      cache[B]={}    â† å…¨æ–°çš„ç¼“å­˜ï¼Œä¸å—Aå½±å“
```

#### å¹¶å‘è¯·æ±‚æ”¯æŒ

ç”±äºUUIDæœºåˆ¶ï¼Œ**å¤©ç„¶æ”¯æŒå¹¶å‘**:

```python
import asyncio

async def process_request(text_chunks, request_id):
    # æ¯ä¸ªè¯·æ±‚æœ‰ç‹¬ç«‹çš„UUIDå’Œç¼“å­˜
    for audio in model.inference_sft_chunked(text_chunks, spk_id="girl_zh"):
        await send_audio(audio, request_id)

# å¹¶å‘å¤„ç†å¤šä¸ªè¯·æ±‚ï¼Œäº’ä¸å¹²æ‰°
await asyncio.gather(
    process_request(["ä½ å¥½", "ä¸–ç•Œ"], request_id=1),  # UUID-AAA
    process_request(["æ—©ä¸Š", "å¥½å•Š"], request_id=2),  # UUID-BBB
    process_request(["æ™šå®‰", "æœ‹å‹"], request_id=3)   # UUID-CCC
)
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
CosyVoice2_MODULE/
â”œâ”€â”€ cosyvoice/              # æ ¸å¿ƒåŒ…
â”‚   â”œâ”€â”€ cli/                # å‘½ä»¤è¡Œæ¥å£
â”‚   â”‚   â”œâ”€â”€ cosyvoice.py    # CosyVoice2ä¸»ç±» (æ–°å¢inference_sft_chunked)
â”‚   â”‚   â”œâ”€â”€ model.py        # æ¨¡å‹å°è£… (UUIDä¼šè¯ç®¡ç†)
â”‚   â”‚   â””â”€â”€ frontend.py     # å‰ç«¯å¤„ç†
â”‚   â”œâ”€â”€ llm/                # è¯­è¨€æ¨¡å‹
â”‚   â”‚   â””â”€â”€ llm.py          # Qwen2LMå®ç° (inference_bistreamæ ¸å¿ƒ)
â”‚   â”œâ”€â”€ flow/               # Flowæ¨¡å‹
â”‚   â”‚   â””â”€â”€ flow.py         # Flow matching (streamingæ”¯æŒ)
â”‚   â”œâ”€â”€ hifigan/            # å£°ç å™¨
â”‚   â”œâ”€â”€ transformer/        # Transformerç»„ä»¶
â”‚   â””â”€â”€ utils/              # å·¥å…·å‡½æ•°
â”œâ”€â”€ matcha/                 # Matcha-TTSä¾èµ–
â”œâ”€â”€ run.py                  # ç¤ºä¾‹è„šæœ¬
â”œâ”€â”€ run_chunked.py          # åˆ†å—æ¨ç†ç¤ºä¾‹ (æ–°æ—§æ–¹æ³•å¯¹æ¯”)
â”œâ”€â”€ __init__.py             # åŒ…åˆå§‹åŒ–
â””â”€â”€ README.md               # æœ¬æ–‡ä»¶
```

## ğŸ”§ é«˜çº§ç”¨æ³•

### æ·»åŠ è‡ªå®šä¹‰é›¶æ ·æœ¬è¯´è¯äºº

```python
from cosyvoice.utils.file_utils import load_wav

# æ·»åŠ æ–°çš„é›¶æ ·æœ¬è¯´è¯äºº
model.add_zero_shot_spk(
    prompt_text="å‚è€ƒæ–‡æœ¬",
    prompt_speech_16k=load_wav('reference.wav', 16000),
    zero_shot_spk_id="custom_speaker"
)

# ä¿å­˜è¯´è¯äººä¿¡æ¯
model.save_spkinfo()

# ä½¿ç”¨è‡ªå®šä¹‰è¯´è¯äºº
for result in model.inference_zero_shot(
    tts_text="æµ‹è¯•æ–‡æœ¬",
    prompt_text="",
    prompt_speech_16k=None,
    zero_shot_spk_id="custom_speaker"
):
    audio = result['tts_speech']
```

### æŸ¥çœ‹å¯ç”¨è¯´è¯äºº

```python
spks = model.list_available_spks()
print("å¯ç”¨è¯´è¯äºº:", spks)
```

## âš ï¸ æ³¨æ„äº‹é¡¹

### æ–‡æœ¬åˆ†å—å»ºè®®

1. **æœ€å°chunkå¤§å°**: å»ºè®®æ¯ä¸ªchunkè‡³å°‘åŒ…å«2-3ä¸ªå­—
   - âŒ ä¸æ¨è: `["äºº", "å·¥", "æ™º", "èƒ½"]` (å•å­—ä¼šå‡ºé”™)
   - âœ… æ¨è: `["äººå·¥", "æ™ºèƒ½", "æŠ€æœ¯"]` (2å­—ä»¥ä¸Š)

2. **è¯­ä¹‰å®Œæ•´æ€§**: å°½é‡åœ¨è¯­ä¹‰å®Œæ•´çš„ä½ç½®åˆ‡åˆ†
   - âœ… å¥½: `["ä»Šå¤©å¤©æ°”å¾ˆå¥½", "é€‚åˆå‡ºå»æ•£æ­¥"]`
   - âš ï¸ å·®: `["ä»Šå¤©å¤©", "æ°”å¾ˆå¥½é€‚", "åˆå‡ºå»"]`

3. **æ€»é•¿åº¦é™åˆ¶**: å»ºè®®å•æ¬¡æ¨ç†æ€»æ–‡æœ¬ä¸è¶…è¿‡200ä¸ªtoken

### å‚æ•°é€‰æ‹©å»ºè®®

- **é»˜è®¤ä½¿ç”¨**: `token_hop_len=15, mel_cache_len=6`
  - å»¶è¿Ÿå’Œæ•ˆç‡çš„æœ€ä½³å¹³è¡¡

- **è¿½æ±‚é€Ÿåº¦**: `token_hop_len=8, mel_cache_len=4`
  - é¦–æ¬¡å“åº”çº¦1.3ç§’,é€‚åˆå®æ—¶å¯¹è¯

- **è¿½æ±‚æ•ˆç‡**: `token_hop_len=25, mel_cache_len=8`
  - RTFæœ€ä¼˜,é€‚åˆæ‰¹å¤„ç†å’Œæ’­æŠ¥

### ç¡¬ä»¶è¦æ±‚

- **CPU**: æ”¯æŒ,ä½†æ¨ç†é€Ÿåº¦è¾ƒæ…¢
- **GPU**: CUDAè®¾å¤‡,æ˜¾è‘—æå‡é€Ÿåº¦
- **Apple Silicon**: æ”¯æŒMPSåŠ é€Ÿ (M1/M2/M3/M4)

### æ¨¡å‹æ–‡ä»¶

ç¡®ä¿æ¨¡å‹ç›®å½•åŒ…å«ä»¥ä¸‹æ–‡ä»¶:
```
CosyVoice2-0.5B/
â”œâ”€â”€ cosyvoice2.yaml          # é…ç½®æ–‡ä»¶
â”œâ”€â”€ llm.pt                   # LLMæƒé‡
â”œâ”€â”€ flow.pt                  # Flowæ¨¡å‹æƒé‡
â”œâ”€â”€ hift.pt                  # å£°ç å™¨æƒé‡
â”œâ”€â”€ campplus.onnx            # è¯´è¯äººç¼–ç å™¨
â”œâ”€â”€ speech_tokenizer_v2.onnx # è¯­éŸ³tokenizer
â”œâ”€â”€ spk2info.pt              # è¯´è¯äººä¿¡æ¯
â””â”€â”€ CosyVoice-BlankEN/       # Qwené¢„è®­ç»ƒæ¨¡å‹
```

## ğŸ› å¸¸è§é—®é¢˜

### Q: åˆ†å—æ¨ç†æ—¶éŸ³é¢‘ä¸è¿è´¯?
A:
1. ç¡®ä¿ä½¿ç”¨`inference_sft_chunked`è€Œä¸æ˜¯å¤šæ¬¡è°ƒç”¨`inference_sft`
2. æ£€æŸ¥chunkæ˜¯å¦åœ¨è¯­ä¹‰å®Œæ•´çš„ä½ç½®åˆ‡åˆ†
3. é€‚å½“å¢å¤§`mel_cache_len`å‚æ•°(å¦‚8æˆ–10)

### Q: é¦–æ¬¡å“åº”å»¶è¿Ÿé«˜?
A:
1. é™ä½`token_hop_len`åˆ°8-10
2. ä½¿ç”¨`stream=True`å¯ç”¨æµå¼æ¨¡å¼
3. å‡å°æ¯ä¸ªchunkçš„å¤§å°

### Q: ç”Ÿæˆçš„éŸ³é¢‘è´¨é‡ä¸å¥½?
A:
1. æ£€æŸ¥å‚è€ƒéŸ³é¢‘è´¨é‡(zero-shotæ¨¡å¼)
2. ç¡®ä¿æ–‡æœ¬å½’ä¸€åŒ–æ­£ç¡®
3. å°è¯•ä¸åŒçš„è¯´è¯äººID

### Q: å†…å­˜å ç”¨è¿‡é«˜?
A:
1. å‡å°`token_hop_len`
2. ä½¿ç”¨æ›´çŸ­çš„æ–‡æœ¬chunk
3. é¿å…åœ¨å•æ¬¡è°ƒç”¨ä¸­å¤„ç†è¿‡é•¿çš„æ–‡æœ¬

## ğŸ“Š æ€§èƒ½åŸºå‡†

åŸºäºCosyVoice2-0.5Bæ¨¡å‹,Apple M4è®¾å¤‡æµ‹è¯•:

| é…ç½® | é¦–æ¬¡å“åº” | RTF | Yieldæ¬¡æ•° | é€‚ç”¨åœºæ™¯ |
|------|---------|-----|----------|---------|
| token_hop_len=8 | 1.26s | 2.24 | 8 | å®æ—¶å¯¹è¯ |
| token_hop_len=15 | 1.47s | 1.53 | 6 | **é€šç”¨æ¨è** |
| token_hop_len=25 | 1.94s | 1.39 | 4 | æ‰¹å¤„ç† |

æµ‹è¯•æ–‡æœ¬: 6ä¸ªçŸ­chunk,æ€»è®¡çº¦3.5ç§’éŸ³é¢‘

## ğŸ”„ æ›´æ–°æ—¥å¿—

### v1.1.0 (2025-11)
- âœ¨ æ–°å¢ `inference_sft_chunked` æ–¹æ³•,æ”¯æŒæµå¼æ–‡æœ¬åˆ†å—æ¨ç†
- âœ¨ æ·»åŠ  `token_hop_len` å’Œ `mel_cache_len` å¯è°ƒå‚æ•°
- ğŸ“ å®Œå–„æ–‡æ¡£å’Œä½¿ç”¨ç¤ºä¾‹
- ğŸ”§ ä¼˜åŒ–é»˜è®¤å‚æ•°é…ç½®

### v1.0.0
- ğŸ‰ åˆå§‹ç‰ˆæœ¬,æ¨¡å—åŒ–å°è£…CosyVoice2
- âœ… æ”¯æŒå¤šç§æ¨ç†æ¨¡å¼
- âœ… æ”¯æŒæµå¼å’Œéæµå¼è¾“å‡º

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäºCosyVoice2å®˜æ–¹å®ç°,éµå¾ªApache 2.0è®¸å¯è¯ã€‚

## ğŸ™ è‡´è°¢

- CosyVoice2å®˜æ–¹å›¢é˜Ÿ
- Qwen2æ¨¡å‹å›¢é˜Ÿ
- ç¤¾åŒºè´¡çŒ®è€…

## ğŸ“® è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®,è¯·æäº¤Issueæˆ–Pull Requestã€‚

---

**å¿«é€Ÿé…ç½®å‚è€ƒ**:
```python
# å®æ—¶å¯¹è¯: token_hop_len=8, mel_cache_len=4
# é€šç”¨æ¨è: token_hop_len=15, mel_cache_len=6  â­
# é«˜è´¨é‡: token_hop_len=25, mel_cache_len=8
```
